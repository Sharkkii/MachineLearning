{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# パーセプトロン"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "「識別関数」を学習することで二値分類問題を解くモデルとしてパーセプトロンというものがある。識別関数とは、${\\bf x}$に対してそれが属するクラス$y$を予測する関数である。このとき、${\\bf x}$がクラス$y$に属する確率は計算されない。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでは${\\bf x}$を2クラス$\\{+1, -1\\}$のいずれかに分類するとする。説明変数${\\bf x}$に対して\n",
    "\n",
    "$$\n",
    "\\hat{y} = a(f({\\bf x}))\n",
    "f({\\bf x}) = {\\bf w}^T {\\bf x}\n",
    "$$\n",
    "\n",
    "によって$y$を予測する。ここで、$a$は活性化関数である。パーセプトロンモデルでは活性化関数としてステップ関数が用いられている。ステップ関数は次のように定義される。\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "a(x) =\n",
    "\\begin{cases}\n",
    "+1 & \\text{ if } x > 0 \\\\\n",
    "-1 & \\text{ if } x < 0\n",
    "\\end{cases}\n",
    "\\end{eqnarray*}\n",
    "\n",
    "よって決定境界は${\\bf w}^T {\\bf x} = 0$という超平面となる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "損失関数を\n",
    "\n",
    "$$\n",
    "L({\\bf w}) \\equiv - \\Sigma_{n, y_n \\neq \\hat{y_n}} {\\bf w}^T {\\bf x_n} y_n\n",
    "$$\n",
    "\n",
    "と定義し、これを最小化するような${\\bf w}$を求める。総和記号の下に書いてあるように、和は誤分類したデータすべてについてとる。誤分類したデータ$({\\bf x}, y)$に対して\n",
    "\n",
    "$$\n",
    "{\\bf w}^T {\\bf x} y < 0 \n",
    "$$\n",
    "\n",
    "が成立するので、損失関数は非負の値をとる。また、分類境界から間違った方向に離れるに従って損失が大きくなることもわかる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "パーセプトロンの学習では、最急降下法によってパラメータ${\\bf w}$を更新する。損失関数の勾配は\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial {\\bf w}} L({\\bf w}) = - \\Sigma_{n, y_n \\neq \\hat{y_n}} {\\bf x_n} y_n\n",
    "$$\n",
    "\n",
    "となるので、更新式は学習率を$\\eta > 0$として\n",
    "\n",
    "$$\n",
    "{\\bf w_{t+1}} = {\\bf w_t} + \\eta \\Sigma_{n, y_n \\neq \\hat{y_n}} {\\bf x_n} y_n\n",
    "$$\n",
    "\n",
    "である。スケーリングに対して予測結果が不変であることを考慮すると、学習率を$\\eta = 1$として良い。よって\n",
    "\n",
    "$$\n",
    "{\\bf w_{t+1}} = {\\bf w_t} + \\Sigma_{n, y_n \\neq \\hat{y_n}} {\\bf x_n} y_n\n",
    "$$\n",
    "\n",
    "とできる。\n",
    "パラメータの更新によって損失関数は減少するが、必ずしも予測が良い方向に動くとは限らない。つまり、それまで正しく分類されていたデータが誤分類するようになる可能性がある。\n",
    "\n",
    "パーセプトロンの収束定理によると、(線形分離できるデータ集合においては)有限回のパラメータ更新によって厳密解に収束する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
